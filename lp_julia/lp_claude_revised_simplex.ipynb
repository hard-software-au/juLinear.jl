{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Simple example of a Julia linear pogramming model\n",
    "#\n",
    "# Convert from notebook to julia program:\n",
    "#   python3 nb_to_jl.py lp_claude_revised_simplex.ipynb\n",
    "#\n",
    " \n",
    "using LinearAlgebra\n",
    "using SparseArrays\n",
    "using Random\n",
    "using ArgParse\n",
    "\n",
    "const DEFAULT_USE_PRESOLVE = true \n",
    "const DEFAULT_USE_INTERIOR_POINT_METHOD = false\n",
    "const DEFAULT_USE_SPARSE_MATRIX = false\n",
    "const DEFAULT_VERBOSE = true\n",
    "\n",
    "global options = Dict()\n",
    "\n",
    "const COMMAND_LINE_OPTION_FILENAME = \"filename\"\n",
    "const COMMAND_LINE_OPTION_USE_PRESOLVE = \"presolve\"\n",
    "const COMMAND_LINE_OPTION_USE_SPARSE_MATRIX = \"sparse\"\n",
    "const COMMAND_LINE_OPTION_USE_INTERIOR_POINT_METHOD = \"interior\"\n",
    "const COMMAND_LINE_OPTION_VERBOSE = \"verbose\"\n",
    "\n",
    "const OPTION_FILENAME = \"filename\"\n",
    "const OPTION_USE_PRESOLVE = \"use_presolve\"\n",
    "const OPTION_USE_SPARSE_MATRIX = \"use_sparse_matrix\"\n",
    "const OPTION_USE_INTERIOR_POINT_METHOD = \"use_interior_point_method\"\n",
    "const OPTION_VERBOSE = \"verbose\"\n",
    "\n",
    "# https://en.wikipedia.org/wiki/Revised_simplex_method\n",
    "const MPS_EXAMPLE::String = \"\"\"\n",
    "NAME          APPLIED_INTEGER_PROGRAMMING_9_7\n",
    "\n",
    "OBJSENSE\n",
    " MAX\n",
    "\n",
    "ROWS\n",
    " N  OBJ\n",
    " L  ROW1\n",
    " L  ROW2\n",
    " L  ROW3\n",
    "\n",
    "COLUMNS\n",
    "    X1        OBJ       4\n",
    "    X1        ROW1      1\n",
    "    X1        ROW2      2\n",
    "    X1        ROW3     -3\n",
    "    X2        OBJ       3\n",
    "    X2        ROW1      2\n",
    "    X2        ROW2     -1\n",
    "    X2        ROW3      2\n",
    "    X3        OBJ       1\n",
    "    X3        ROW1      3\n",
    "    X3        ROW2      2\n",
    "    X3        ROW3      1\n",
    "    X4        OBJ       7\n",
    "    X4        ROW1      1\n",
    "    X4        ROW2      2\n",
    "    X4        ROW3     -1\n",
    "    X5        OBJ       6\n",
    "    X5        ROW1     -3\n",
    "    X5        ROW2      1\n",
    "    X5        ROW3      2\n",
    "\n",
    "RHS\n",
    "    RHS1      ROW1      9\n",
    "    RHS1      ROW2     10\n",
    "    RHS1      ROW3     11\n",
    "\n",
    "BOUNDS\n",
    " LO BOUND1    X1        0\n",
    " LO BOUND1    X2        0\n",
    " LO BOUND1    X3        0\n",
    " LO BOUND1    X4        0\n",
    " LO BOUND1    X5        0\n",
    "\n",
    "ENDATA\n",
    "\"\"\"\n",
    "#=\n",
    "/opt/homebrew/Cellar/highs/1.7.2/bin/highs --solution_file ex97_highs.txt ex97.mps\n",
    "Running HiGHS 1.7.2 (git hash: n/a): Copyright (c) 2024 HiGHS under MIT licence terms\n",
    "LP   ex97 has 3 rows; 5 cols; 15 nonzeros\n",
    "Coefficient ranges:\n",
    "  Matrix [1e+00, 3e+00]\n",
    "  Cost   [1e+00, 7e+00]\n",
    "  Bound  [0e+00, 0e+00]\n",
    "  RHS    [9e+00, 1e+01]\n",
    "Presolving model\n",
    "3 rows, 5 cols, 15 nonzeros  0s\n",
    "3 rows, 5 cols, 15 nonzeros  0s\n",
    "Presolve : Reductions: rows 3(-0); columns 5(-0); elements 15(-0) - Not reduced\n",
    "Problem not reduced by presolve: solving the LP\n",
    "Using EKK dual simplex solver - serial\n",
    "  Iteration        Objective     Infeasibilities num(sum)\n",
    "          0    -2.0999978563e+01 Ph1: 3(11); Du: 5(21) 0s\n",
    "          4     9.4000000000e+01 Pr: 0(0) 0s\n",
    "Model   status      : Optimal\n",
    "Simplex   iterations: 4\n",
    "Objective value     :  9.4000000000e+01\n",
    "HiGHS run time      :          0.00\n",
    "\n",
    "Model status\n",
    "Optimal\n",
    "\n",
    "# Primal solution values\n",
    "Feasible\n",
    "Objective 94\n",
    "# Columns 5\n",
    "X1 7\n",
    "X2 10\n",
    "X3 0\n",
    "X4 0\n",
    "X5 6\n",
    "# Rows 3\n",
    "ROW1 9\n",
    "ROW2 10\n",
    "ROW3 11\n",
    "\n",
    "# Dual solution values\n",
    "Feasible\n",
    "# Columns 5\n",
    "X1 0\n",
    "X2 0\n",
    "X3 -16.4285714285714\n",
    "X4 -2.2380952380952\n",
    "X5 0\n",
    "# Rows 3\n",
    "ROW1 1.4761904761905\n",
    "ROW2 5.1904761904762\n",
    "ROW3 2.6190476190476\n",
    "\n",
    "# Basis\n",
    "HiGHS v1\n",
    "Valid\n",
    "# Columns 5\n",
    "1 1 0 0 1 \n",
    "# Rows 3\n",
    "2 2 2 \n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function is_running_in_notebook()\n",
    "    # Check if running in VS Code's Jupyter notebook environment\n",
    "    if (haskey(ENV, \"VSCODE_PID\") || haskey(ENV, \"VSCODE_CWD\"))\n",
    "        return true\n",
    "    # Check if running in a general Jupyter environment (including VS Code)\n",
    "    elseif isdefined(Main, :IJulia) && Main.IJulia.inited\n",
    "        return true\n",
    "    else\n",
    "        return false\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function parse_commandline()\n",
    "    s = ArgParseSettings()\n",
    "\n",
    "    @add_arg_table s begin\n",
    "        \"--filename\", \"-f\"\n",
    "            help = \"path to the problem file (mps format)\"\n",
    "            arg_type = String\n",
    "            required = true\n",
    "        \"--interior\", \"-i\"\n",
    "            help = \"use interior point method (LP only)\"\n",
    "            arg_type = Bool           \n",
    "        \"--min\"\n",
    "            help = \"minimization of the objective function\"\n",
    "            action = :store_true            \n",
    "        \"--max\"\n",
    "            help = \"maximization of the objective function\"\n",
    "            action = :store_true            \n",
    "        \"--presolve\"\n",
    "            help = \"use presolve (default true)\"\n",
    "            arg_type = Bool          \n",
    "        \"--simplex\"\n",
    "            help = \"use simplex method (default)\"\n",
    "            arg_type = Bool          \n",
    "        \"--sparse\", \"-s\"\n",
    "            help = \"use sparce matrix representation\"\n",
    "            arg_type = Bool\n",
    "        \"--verbose\", \"-v\"\n",
    "            help = \"verbose output\"\n",
    "            action = :store_true\n",
    "    end\n",
    "\n",
    "    return parse_args(s)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a struct to represent a Linear Programming problem\n",
    "struct LPProblem\n",
    "    is_minimize::Bool  # True if the objective is to minimize\n",
    "    c::Vector{Float64}  # Objective function coefficients\n",
    "    A::Matrix{Float64}  # Constraint matrix\n",
    "    b::Vector{Float64}  # Right-hand side of constraints\n",
    "    vars::Vector{String}  # Variable names\n",
    "    constraint_types::Vector{Char}  # Constraint types\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function read_mps_from_string(mps_string::String)\n",
    "    lines = split(mps_string, '\\n')\n",
    "    sections = Dict(\"NAME\" => \"\", \"ROWS\" => [], \"COLUMNS\" => Dict(), \"RHS\" => Dict(), \"BOUNDS\" => Dict())\n",
    "    current_section = \"\"\n",
    "    objective_name = \"\"\n",
    "    is_minimize = true\n",
    "\n",
    "    for line in lines\n",
    "        words = split(line)\n",
    "        (isempty(words) || (line[1] == '*')) && continue  # Skip empty lines and comments\n",
    "\n",
    "        if (line[1] != ' ') && words[1] in [\"NAME\", \"OBJSENSE\", \"ROWS\", \"COLUMNS\", \"RHS\", \"BOUNDS\", \"ENDATA\"]\n",
    "            current_section = words[1]\n",
    "            continue\n",
    "        end\n",
    "\n",
    "        if current_section == \"NAME\"\n",
    "            sections[\"NAME\"] = words[1]\n",
    "        elseif current_section == \"OBJSENSE\"\n",
    "            if words[1] == \"MAX\"\n",
    "                is_minimize = false\n",
    "            end\n",
    "        elseif current_section == \"ROWS\"\n",
    "            row_type, row_name = words\n",
    "            push!(sections[\"ROWS\"], (type=row_type, name=row_name))\n",
    "            if row_type == \"N\"\n",
    "                objective_name = row_name\n",
    "            end\n",
    "        elseif current_section == \"COLUMNS\"\n",
    "            col_name, row_name, value = words\n",
    "            value = parse(Float64, value)\n",
    "            if !haskey(sections[\"COLUMNS\"], col_name)\n",
    "                sections[\"COLUMNS\"][col_name] = Dict()\n",
    "            end\n",
    "            sections[\"COLUMNS\"][col_name][row_name] = value\n",
    "        elseif current_section == \"RHS\"\n",
    "            if length(words) == 3\n",
    "                _, row_name, value = words\n",
    "            else\n",
    "                row_name, value = words[2:3]\n",
    "            end\n",
    "            sections[\"RHS\"][row_name] = parse(Float64, value)\n",
    "        elseif current_section == \"BOUNDS\"\n",
    "            bound_type, _, var_name, value = words\n",
    "            if !haskey(sections[\"BOUNDS\"], var_name)\n",
    "                sections[\"BOUNDS\"][var_name] = Dict()\n",
    "            end\n",
    "            sections[\"BOUNDS\"][var_name][bound_type] = parse(Float64, value)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Convert to LPProblem structure\n",
    "    vars = collect(keys(sections[\"COLUMNS\"]))\n",
    "    n_vars = length(vars)\n",
    "    n_constraints = count(row -> row.type != \"N\", sections[\"ROWS\"])\n",
    "\n",
    "    c = zeros(n_vars)\n",
    "    A = zeros(n_constraints, n_vars)\n",
    "    b = zeros(n_constraints)\n",
    "    constraint_types = Char[]\n",
    "\n",
    "    # Populate objective function\n",
    "    for (i, var) in enumerate(vars)\n",
    "        if haskey(sections[\"COLUMNS\"][var], objective_name)\n",
    "            c[i] = sections[\"COLUMNS\"][var][objective_name]\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Populate constraint matrix and right-hand side\n",
    "    constraint_index = 0\n",
    "    for row in sections[\"ROWS\"]\n",
    "        if row.type != \"N\"\n",
    "            constraint_index += 1\n",
    "            push!(constraint_types, row.type[1])  # Store constraint type\n",
    "            for (i, var) in enumerate(vars)\n",
    "                if haskey(sections[\"COLUMNS\"][var], row.name)\n",
    "                    A[constraint_index, i] = sections[\"COLUMNS\"][var][row.name]\n",
    "                end\n",
    "            end\n",
    "            b[constraint_index] = get(sections[\"RHS\"], row.name, 0.0)\n",
    "            \n",
    "            # Adjust for 'G' type constraints\n",
    "            if row.type == \"G\"\n",
    "                A[constraint_index, :] *= -1\n",
    "                b[constraint_index] *= -1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Process bound constraints\n",
    "    lb = fill(-Inf, n_vars)\n",
    "    ub = fill(Inf, n_vars)\n",
    "    for (i, var) in enumerate(vars)\n",
    "        if haskey(sections[\"BOUNDS\"], var)\n",
    "            bounds = sections[\"BOUNDS\"][var]\n",
    "            if haskey(bounds, \"LO\")\n",
    "                lb[i] = bounds[\"LO\"]\n",
    "            end\n",
    "            if haskey(bounds, \"UP\")\n",
    "                ub[i] = bounds[\"UP\"]\n",
    "            end\n",
    "            if haskey(bounds, \"FX\")\n",
    "                lb[i] = ub[i] = bounds[\"FX\"]\n",
    "            end\n",
    "        else\n",
    "            lb[i] = 0.0  # Default lower bound is 0 if not specified\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Add bound constraints to A and b\n",
    "    n_bound_constraints = count(x -> x > -Inf, lb) + count(x -> x < Inf, ub)\n",
    "    A_with_bounds = zeros(n_constraints + n_bound_constraints, n_vars)\n",
    "    b_with_bounds = zeros(n_constraints + n_bound_constraints)\n",
    "    \n",
    "    A_with_bounds[1:n_constraints, :] = A\n",
    "    b_with_bounds[1:n_constraints] = b\n",
    "    \n",
    "    bound_constraint_index = n_constraints\n",
    "    for i in 1:n_vars\n",
    "        if lb[i] > -Inf\n",
    "            bound_constraint_index += 1\n",
    "            A_with_bounds[bound_constraint_index, i] = 1\n",
    "            b_with_bounds[bound_constraint_index] = lb[i]\n",
    "            push!(constraint_types, 'G')\n",
    "        end\n",
    "        if ub[i] < Inf\n",
    "            bound_constraint_index += 1\n",
    "            A_with_bounds[bound_constraint_index, i] = 1\n",
    "            b_with_bounds[bound_constraint_index] = ub[i]\n",
    "            push!(constraint_types, 'L')\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return LPProblem(is_minimize, c, A_with_bounds, b_with_bounds, vars, constraint_types)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function presolve(lp::LPProblem; eps::Float64=1e-8)\n",
    "    is_minimize, c, A, b = lp.is_minimize, lp.c, sparse(lp.A), lp.b\n",
    "    vars, constraint_types = lp.vars, lp.constraint_types\n",
    "    m, n = size(A)\n",
    "\n",
    "    # Initialize masks for rows and columns to keep\n",
    "    keep_rows = trues(m)\n",
    "    keep_cols = trues(n)\n",
    "\n",
    "    # Step 1: Remove zero columns\n",
    "    for j in 1:n\n",
    "        if nnz(A[:, j]) == 0 && abs(c[j]) < eps\n",
    "            keep_cols[j] = false\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Step 2: Remove zero rows\n",
    "    for i in 1:m\n",
    "        if nnz(A[i, :]) == 0\n",
    "            if abs(b[i]) < eps\n",
    "                keep_rows[i] = false\n",
    "            else\n",
    "                error(\"Infeasible problem: zero row with non-zero RHS\")\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Step 3: Remove duplicate rows\n",
    "    for i in 1:m\n",
    "        if !keep_rows[i]\n",
    "            continue\n",
    "        end\n",
    "        for j in (i+1):m\n",
    "            if !keep_rows[j]\n",
    "                continue\n",
    "            end\n",
    "            if A[i, :] ≈ A[j, :] && abs(b[i] - b[j]) < eps && constraint_types[i] == constraint_types[j]\n",
    "                keep_rows[j] = false\n",
    "            elseif A[i, :] ≈ -A[j, :] && abs(b[i] + b[j]) < eps && \n",
    "                   ((constraint_types[i] == '≤' && constraint_types[j] == '≥') || \n",
    "                    (constraint_types[i] == '≥' && constraint_types[j] == '≤'))\n",
    "                keep_rows[j] = false\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Step 4: Fix variables and tighten bounds\n",
    "    fixed_vars = Dict{String, Float64}()\n",
    "    for j in 1:n\n",
    "        col = A[:, j]\n",
    "        if nnz(col) == 1\n",
    "            i = findfirst(!iszero, col)\n",
    "            if abs(col[i]) ≈ 1 && constraint_types[i] == '='\n",
    "                val = b[i] / col[i]\n",
    "                fixed_vars[vars[j]] = val\n",
    "                keep_cols[j] = false\n",
    "                b .-= val * col\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Apply the reductions\n",
    "    A_new = A[keep_rows, keep_cols]\n",
    "    b_new = b[keep_rows]\n",
    "    c_new = c[keep_cols]\n",
    "    vars_new = vars[keep_cols]\n",
    "    constraint_types_new = constraint_types[keep_rows]\n",
    "\n",
    "    # Adjust the objective for fixed variables\n",
    "    obj_adjust = isempty(fixed_vars) ? 0.0 : sum(c[j] * val for (j, val) in enumerate(lp.vars) if haskey(fixed_vars, val))\n",
    "\n",
    "    if options[OPTION_VERBOSE]\n",
    "        println(\"Presolve summary:\")\n",
    "        println(\"Original problem size: $(m) x $(n)\")\n",
    "        println(\"Reduced problem size: $(sum(keep_rows)) x $(sum(keep_cols))\")\n",
    "        println(\"Number of fixed variables: $(length(fixed_vars))\")\n",
    "        println(\"Objective adjustment: $obj_adjust\")\n",
    "    end\n",
    "\n",
    "    return LPProblem(is_minimize, c_new, Matrix(A_new), b_new, vars_new, constraint_types_new), fixed_vars, obj_adjust\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=\n",
    "Theoretical basis for each step:\n",
    "\n",
    "Problem Formulation:\n",
    "\n",
    "The Revised Simplex Method solves linear programming problems in the standard form:\n",
    "Maximize c^T x\n",
    "Subject to Ax = b\n",
    "x ≥ 0\n",
    "\n",
    "\n",
    "Slack Variables (Step 0):\n",
    "\n",
    "Slack variables are added to convert inequality constraints to equality constraints.\n",
    "This ensures that the problem is in standard form for the simplex method.\n",
    "\n",
    "\n",
    "Basic and Non-Basic Variables:\n",
    "\n",
    "The method partitions variables into basic (B) and non-basic (N) variables.\n",
    "Initially, slack variables form the basis, corresponding to the identity matrix in the augmented constraint matrix.\n",
    "\n",
    "\n",
    "Revised Simplex Iteration:\n",
    "a. Basic Solution (Step 1):\n",
    "\n",
    "Compute x_B = B^(-1) * b, where B is the basis matrix.\n",
    "This gives the values of basic variables in the current solution.\n",
    "\n",
    "b. Reduced Costs (Step 2):\n",
    "\n",
    "Compute y = c_B' * B^(-1), where c_B are the objective coefficients of basic variables.\n",
    "Calculate reduced costs: c_N - y' * A_N, where A_N are columns of non-basic variables.\n",
    "Reduced costs measure the rate of change in the objective for unit increase in non-basic variables.\n",
    "\n",
    "c. Optimality Check (Step 3):\n",
    "\n",
    "If all reduced costs are non-positive, the current solution is optimal.\n",
    "This is based on the theorem that a basic feasible solution is optimal if and only if all reduced costs are non-positive.\n",
    "\n",
    "d. Entering Variable (Step 4):\n",
    "\n",
    "Choose the non-basic variable with the most positive reduced cost to enter the basis.\n",
    "This variable has the potential to improve the objective value the most.\n",
    "\n",
    "e. Direction Computation (Step 5):\n",
    "\n",
    "Compute d = B^(-1) * A_q, where A_q is the column of the entering variable.\n",
    "This determines how basic variables change as the entering variable increases.\n",
    "\n",
    "f. Unboundedness Check (Step 6):\n",
    "\n",
    "If all elements of d are non-positive and the reduced cost is positive, the problem is unbounded.\n",
    "This means we can increase the entering variable indefinitely, improving the objective without bound.\n",
    "\n",
    "g. Leaving Variable (Step 7):\n",
    "\n",
    "Perform the minimum ratio test: min(x_B_i / d_i) for d_i > 0.\n",
    "This determines how far we can move along the edge without violating non-negativity constraints.\n",
    "\n",
    "h. Basis Update (Step 8):\n",
    "\n",
    "Swap the entering and leaving variables in the basis.\n",
    "This moves to an adjacent extreme point of the feasible region.\n",
    "\n",
    "\n",
    "Convergence:\n",
    "\n",
    "The algorithm repeats these steps until optimality is reached or unboundedness is detected.\n",
    "Each iteration either improves the objective value or determines that the problem is unbounded.\n",
    "For non-degenerate problems, the algorithm is guaranteed to terminate in a finite number of steps.\n",
    "\n",
    "\n",
    "Numerical Considerations:\n",
    "\n",
    "Small tolerance (1e-10) is used for numerical stability in comparisons.\n",
    "A maximum iteration limit prevents infinite loops in case of cycling (rare in practice, but possible in degenerate problems).\n",
    "\n",
    "This implementation of the Revised Simplex Method efficiently solves linear programming problems by working with the inverse of the basis matrix and reduced costs, rather than maintaining the entire tableau as in the standard Simplex Method.\n",
    "=#\n",
    "\n",
    "function revised_simplex(lp::LPProblem)\n",
    "    c, A, b = lp.c, lp.A, lp.b\n",
    "    m, n = size(A)\n",
    "    \n",
    "    # If minimizing, negate the objective function to convert to a maximization problem\n",
    "    if lp.is_minimize\n",
    "        c = -c\n",
    "    end\n",
    "    \n",
    "    println(\"\\nInitial problem:\")\n",
    "    println(\"Objective function coefficients c: \", lp.c)\n",
    "    println(\"Constraint matrix A: \", lp.A)\n",
    "    println(\"Right-hand side b: \", lp.b)\n",
    "    println(\"Variables: \", lp.vars) \n",
    "    println(\"Optimization type: \", lp.is_minimize ? \"Minimize\" : \"Maximize\")\n",
    "    \n",
    "    # Step 0: Add slack variables to convert inequalities to equalities\n",
    "    A = [A I(m)]  # Augment A with identity matrix for slack variables\n",
    "    c = [c; zeros(m)]  # Extend objective coefficients with zeros for slack variables\n",
    "    n = n + m  # Update number of variables\n",
    "    \n",
    "    # Initialize basis with slack variables\n",
    "    B = collect(n-m+1:n)  # Indices of basic variables\n",
    "    N = collect(1:n-m)    # Indices of non-basic variables\n",
    "    \n",
    "    println(\"Initial basis: \", B)\n",
    "    println(\"Initial non-basic variables: \", N)\n",
    "    \n",
    "    iteration = 0\n",
    "    while true\n",
    "        iteration += 1\n",
    "        println(\"\\nIteration \", iteration)\n",
    "        \n",
    "        # Step 1: Compute basic solution\n",
    "        B_matrix = A[:, B]  # Extract basis matrix\n",
    "        x_B = B_matrix \\ b  # Solve B * x_B = b for basic variables\n",
    "        \n",
    "        println(\"Basic solution: \", x_B)\n",
    "        \n",
    "        # Step 2: Compute reduced costs\n",
    "        y = (c[B]' / B_matrix)'  # Compute dual variables: y' * B = c_B'\n",
    "        c_N = c[N] - A[:, N]' * y  # Compute reduced costs for non-basic variables\n",
    "        \n",
    "        println(\"Reduced costs: \", c_N)\n",
    "        \n",
    "        # Step 3: Check optimality\n",
    "        if all(c_N .<= 1e-10)  # If all reduced costs are non-positive, solution is optimal\n",
    "            x = zeros(n)\n",
    "            x[B] = x_B\n",
    "            println(\"Optimal solution found\")\n",
    "            obj_value = dot(c[1:length(lp.vars)], x[1:length(lp.vars)])\n",
    "            if lp.is_minimize\n",
    "                obj_value = -obj_value  # Convert back to minimization objective\n",
    "            end\n",
    "            return x[1:length(lp.vars)], obj_value\n",
    "        end\n",
    "        \n",
    "        # Step 4: Choose entering variable (most positive reduced cost)\n",
    "        e = argmax(c_N)\n",
    "        q = N[e]\n",
    "        \n",
    "        println(\"Entering variable: \", q)\n",
    "        \n",
    "        # Step 5: Compute direction of edge to traverse\n",
    "        d = B_matrix \\ A[:, q]\n",
    "        \n",
    "        println(\"Direction: \", d)\n",
    "        \n",
    "        # Step 6: Check unboundedness\n",
    "        if all(d .<= 1e-10)  # If direction is non-positive, problem is unbounded\n",
    "            error(\"Problem is unbounded\")\n",
    "        end\n",
    "        \n",
    "        # Step 7: Choose leaving variable (minimum ratio test)\n",
    "        ratios = x_B ./ d\n",
    "        ratios[d .<= 1e-10] .= Inf  # Avoid division by zero or negative values\n",
    "        l = argmin(filter(x -> x > 0, ratios))\n",
    "        \n",
    "        p = B[l]\n",
    "        println(\"Leaving variable: \", p)\n",
    "        \n",
    "        # Step 8: Update basis\n",
    "        B[l] = q\n",
    "        N[e] = p\n",
    "        \n",
    "        println(\"New basis: \", B)\n",
    "        println(\"New non-basic variables: \", N)\n",
    "        \n",
    "        # Safeguard against infinite loops\n",
    "        if iteration > 100\n",
    "            println(\"Maximum iterations reached\")\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    error(\"Algorithm did not converge\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function revised_simplex_sparse(lp::LPProblem)\n",
    "    c, A, b = lp.c, sparse(lp.A), lp.b\n",
    "    m, n = size(A)\n",
    "    \n",
    "    # If minimizing, negate the objective function to convert to a maximization problem\n",
    "    if lp.is_minimize\n",
    "        c = -c\n",
    "    end\n",
    "    \n",
    "    println(\"\\nInitial problem:\")\n",
    "    println(\"Objective function coefficients c: \", lp.c)\n",
    "    println(\"Constraint matrix A: \", lp.A)\n",
    "    println(\"Right-hand side b: \", lp.b)\n",
    "    println(\"Variables: \", lp.vars)\n",
    "    println(\"Optimization type: \", lp.is_minimize ? \"Minimize\" : \"Maximize\")\n",
    "    \n",
    "    # Step 0: Add slack variables to convert inequalities to equalities\n",
    "    A = [A sparse(I, m, m)]  # Augment A with sparse identity matrix for slack variables\n",
    "    c = [c; zeros(m)]  # Extend objective coefficients with zeros for slack variables\n",
    "    n = n + m  # Update number of variables\n",
    "    \n",
    "    # Initialize basis with slack variables\n",
    "    B = collect(n-m+1:n)  # Indices of basic variables\n",
    "    N = collect(1:n-m)    # Indices of non-basic variables\n",
    "    \n",
    "    println(\"Initial basis: \", B)\n",
    "    println(\"Initial non-basic variables: \", N)\n",
    "    \n",
    "    iteration = 0\n",
    "    while true\n",
    "        iteration += 1\n",
    "        println(\"\\nIteration \", iteration)\n",
    "        \n",
    "        # Step 1: Compute basic solution\n",
    "        B_matrix = A[:, B]  # Extract basis matrix\n",
    "        x_B = B_matrix \\ Vector(b)  # Solve B * x_B = b for basic variables\n",
    "        \n",
    "        println(\"Basic solution: \", x_B)\n",
    "        \n",
    "        # Step 2: Compute reduced costs\n",
    "        y = (Vector(c[B])' / B_matrix)'  # Compute dual variables: y' * B = c_B'\n",
    "        c_N = c[N] - A[:, N]' * y  # Compute reduced costs for non-basic variables\n",
    "        \n",
    "        println(\"Reduced costs: \", c_N)\n",
    "        \n",
    "        # Step 3: Check optimality\n",
    "        if all(c_N .<= 1e-10)  # If all reduced costs are non-positive, solution is optimal\n",
    "            x = spzeros(n)\n",
    "            x[B] = x_B\n",
    "            println(\"Optimal solution found\")\n",
    "            obj_value = dot(c[1:length(lp.vars)], x[1:length(lp.vars)])\n",
    "            if lp.is_minimize\n",
    "                obj_value = -obj_value  # Convert back to minimization objective\n",
    "            end\n",
    "            return Array(x[1:length(lp.vars)]), obj_value\n",
    "        end\n",
    "        \n",
    "        # Step 4: Choose entering variable (most positive reduced cost)\n",
    "        e = argmax(c_N)\n",
    "        q = N[e]\n",
    "        \n",
    "        println(\"Entering variable: \", q)\n",
    "        \n",
    "        # Step 5: Compute direction of edge to traverse\n",
    "        d = B_matrix \\ Vector(A[:, q])  # Convert sparse column to dense vector\n",
    "        \n",
    "        println(\"Direction: \", d)\n",
    "        \n",
    "        # Step 6: Check unboundedness\n",
    "        if all(d .<= 1e-10)  # If direction is non-positive, problem is unbounded\n",
    "            error(\"Problem is unbounded\")\n",
    "        end\n",
    "        \n",
    "        # Step 7: Choose leaving variable (minimum ratio test)\n",
    "        ratios = x_B ./ d\n",
    "        ratios[d .<= 1e-10] .= Inf  # Avoid division by zero or negative values\n",
    "        l = argmin(filter(x -> x > 0, ratios))\n",
    "        \n",
    "        p = B[l]\n",
    "        println(\"Leaving variable: \", p)\n",
    "        \n",
    "        # Step 8: Update basis\n",
    "        B[l] = q\n",
    "        N[e] = p\n",
    "        \n",
    "        println(\"New basis: \", B)\n",
    "        println(\"New non-basic variables: \", N)\n",
    "        \n",
    "        # Safeguard against infinite loops\n",
    "        if iteration > 100\n",
    "            println(\"Maximum iterations reached\")\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    error(\"Algorithm did not converge\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function count_nonzeros(A)\n",
    "    return count(!iszero, A)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function scale_problem!(A, b, c)\n",
    "    println(\"Entering scale_problem!\")\n",
    "    m, n = size(A)\n",
    "    println(\"Matrix dimensions: $m x $n\")\n",
    "    \n",
    "    row_scale = 1 ./ max.(1e-8, sqrt.(sum(abs2, A, dims=2)[:]))\n",
    "    col_scale = 1 ./ max.(1e-8, sqrt.(sum(abs2, A, dims=1)[:]))\n",
    "    \n",
    "    println(\"Row scaling range: [$(minimum(row_scale)), $(maximum(row_scale))]\")\n",
    "    println(\"Column scaling range: [$(minimum(col_scale)), $(maximum(col_scale))]\")\n",
    "    \n",
    "    A ./= row_scale\n",
    "    A ./= col_scale'\n",
    "    b ./= row_scale\n",
    "    c ./= col_scale\n",
    "    \n",
    "    println(\"Scaled matrix range: [$(minimum(abs.(A))), $(maximum(abs.(A)))]\")\n",
    "    println(\"Scaled RHS range: [$(minimum(abs.(b))), $(maximum(abs.(b)))]\")\n",
    "    println(\"Scaled cost range: [$(minimum(abs.(c))), $(maximum(abs.(c)))]\")\n",
    "    \n",
    "    println(\"Exiting scale_problem!\")\n",
    "    return row_scale, col_scale\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function mehrotra_predictor_corrector(A, b, c, x, y, s, mu)\n",
    "    println(\"Entering mehrotra_predictor_corrector\")\n",
    "    m, n = size(A)\n",
    "    println(\"Matrix dimensions: $m x $n\")\n",
    "    \n",
    "    # Predictor step\n",
    "    rx = A' * y + s - c\n",
    "    ry = A * x - b\n",
    "    rs = x .* s\n",
    "    \n",
    "    println(\"Residual norms: rx=$(norm(rx)), ry=$(norm(ry)), rs=$(norm(rs))\")\n",
    "    \n",
    "    D = Diagonal(@. sqrt(max(x, 1e-16) / max(s, 1e-16)))\n",
    "    M = [A * D * D * A' A * D;\n",
    "         D * A' Diagonal(s)]\n",
    "    rhs = [-ry; -rx]\n",
    "    \n",
    "    println(\"M dimensions: $(size(M))\")\n",
    "    println(\"rhs dimensions: $(size(rhs))\")\n",
    "    \n",
    "    # Use QR factorization for better numerical stability\n",
    "    F = qr(M)\n",
    "    dz = F \\ rhs\n",
    "    \n",
    "    dy_aff = dz[1:m]\n",
    "    dx_aff = D * (D * (dz[m+1:end] - A' * dy_aff))\n",
    "    ds_aff = -rx - A' * dy_aff\n",
    "    \n",
    "    println(\"Affine step norms: dx_aff=$(norm(dx_aff)), dy_aff=$(norm(dy_aff)), ds_aff=$(norm(ds_aff))\")\n",
    "    \n",
    "    # Compute centering parameter\n",
    "    alpha_aff_p = min(1.0, minimum(-x ./ dx_aff[dx_aff .< 0]))\n",
    "    alpha_aff_d = min(1.0, minimum(-s ./ ds_aff[ds_aff .< 0]))\n",
    "    mu_aff = dot(x + alpha_aff_p * dx_aff, s + alpha_aff_d * ds_aff) / n\n",
    "    sigma = max(0, min(1, (mu_aff / mu)^3))\n",
    "    \n",
    "    println(\"Centering parameter: sigma=$sigma\")\n",
    "    \n",
    "    # Corrector step\n",
    "    rhs = [-ry; -rx - rs ./ max.(x, 1e-16) + sigma * mu ./ max.(x, 1e-16) - dx_aff .* ds_aff ./ max.(x, 1e-16)]\n",
    "    dz = F \\ rhs\n",
    "    dy = dz[1:m]\n",
    "    dx = D * (D * (dz[m+1:end] - A' * dy))\n",
    "    ds = -rx - A' * dy\n",
    "    \n",
    "    println(\"Corrector step norms: dx=$(norm(dx)), dy=$(norm(dy)), ds=$(norm(ds))\")\n",
    "    \n",
    "    println(\"Exiting mehrotra_predictor_corrector\")\n",
    "    return dx, dy, ds, sigma\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function highs_inspired_ipm(lp::LPProblem; max_iter=100, tol=1e-8)\n",
    "    println(\"Entering highs_inspired_ipm\")\n",
    "    c, A, b = copy(lp.c), copy(lp.A), copy(lp.b)\n",
    "    m, n = size(A)\n",
    "    \n",
    "    println(\"Problem dimensions: $m rows, $n columns\")\n",
    "    println(\"Nonzeros in A: $(count_nonzeros(A))\")\n",
    "    \n",
    "    # Scale the problem\n",
    "    row_scale, col_scale = scale_problem!(A, b, c)\n",
    "    println(\"Scaling applied\")\n",
    "    \n",
    "    # Initialize variables\n",
    "    x = ones(n)\n",
    "    y = zeros(m)\n",
    "    s = ones(n)\n",
    "    \n",
    "    # Initial mu\n",
    "    mu = dot(x, s) / n\n",
    "    println(\"Initial mu: $mu\")\n",
    "    \n",
    "    for k in 1:max_iter\n",
    "        # Compute residuals\n",
    "        primal_res = norm(A * x - b) / (1 + norm(b))\n",
    "        dual_res = norm(A' * y + s - c) / (1 + norm(c))\n",
    "        \n",
    "        # Compute objective values\n",
    "        primal_obj = dot(c, x)\n",
    "        dual_obj = dot(b, y)\n",
    "        \n",
    "        println(\"Iter $k: P.res = $primal_res, D.res = $dual_res, P.obj = $primal_obj, D.obj = $dual_obj, mu = $mu\")\n",
    "        \n",
    "        # Check for convergence\n",
    "        if primal_res < tol && dual_res < tol && (primal_obj - dual_obj) / (1 + abs(primal_obj)) < tol\n",
    "            println(\"Optimal solution found\")\n",
    "            return x .* col_scale, primal_obj\n",
    "        end\n",
    "        \n",
    "        # Mehrotra predictor-corrector\n",
    "        dx, dy, ds, sigma = mehrotra_predictor_corrector(A, b, c, x, y, s, mu)\n",
    "        \n",
    "        println(\"dx dimensions: $(size(dx)), x dimensions: $(size(x))\")\n",
    "        println(\"ds dimensions: $(size(ds)), s dimensions: $(size(s))\")\n",
    "        \n",
    "        # Compute step sizes with safeguards\n",
    "        function safe_step_size(current, delta)\n",
    "            if length(current) != length(delta)\n",
    "                error(\"Dimension mismatch: current=$(length(current)), delta=$(length(delta))\")\n",
    "            end\n",
    "            ratios = -current ./ delta\n",
    "            valid_ratios = filter(r -> isfinite(r) && r > 0, ratios)\n",
    "            return isempty(valid_ratios) ? 0.9995 : min(0.9995, minimum(valid_ratios))\n",
    "        end\n",
    "        \n",
    "        alpha_pri = safe_step_size(x, dx)\n",
    "        alpha_dual = safe_step_size(s, ds)\n",
    "        \n",
    "        println(\"Step sizes: alpha_pri=$alpha_pri, alpha_dual=$alpha_dual\")\n",
    "        \n",
    "        # Update variables\n",
    "        x .+= alpha_pri .* dx\n",
    "        y .+= alpha_dual .* dy\n",
    "        s .+= alpha_dual .* ds\n",
    "        \n",
    "        # Update mu\n",
    "        mu = dot(x, s) / n * sigma\n",
    "        \n",
    "        println(\"Updated mu: $mu\")\n",
    "        \n",
    "        # Multiple centrality corrections (simplified version)\n",
    "        for cc_iter in 1:2\n",
    "            rx = c - A' * y - s\n",
    "            ry = b - A * x\n",
    "            rs = x .* s\n",
    "            if norm(rs .- mu) < 0.1 * mu\n",
    "                println(\"Centrality correction converged after $cc_iter iterations\")\n",
    "                break\n",
    "            end\n",
    "            dx_cc, dy_cc, ds_cc, _ = mehrotra_predictor_corrector(A, b, c, x, y, s, mu)\n",
    "            alpha_cc = safe_step_size(x, dx_cc)\n",
    "            x .+= 0.5 .* alpha_cc .* dx_cc\n",
    "            y .+= 0.5 .* alpha_cc .* dy_cc\n",
    "            s .+= 0.5 .* alpha_cc .* ds_cc\n",
    "            println(\"Centrality correction step size: $alpha_cc\")\n",
    "        end\n",
    "        \n",
    "        # Ensure positivity\n",
    "        x .= max.(x, 1e-8)\n",
    "        s .= max.(s, 1e-8)\n",
    "        \n",
    "        println(\"Min x: $(minimum(x)), Min s: $(minimum(s))\")\n",
    "    end\n",
    "    \n",
    "    println(\"Maximum iterations reached without convergence\")\n",
    "    println(\"Exiting highs_inspired_ipm\")\n",
    "    return x .* col_scale, dot(c, x)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main program\n",
    "\n",
    "if is_running_in_notebook()\n",
    "    println(\"Running as a notebook\")    \n",
    "else\n",
    "    println(\"Running as a script\")\n",
    "end\n",
    "\n",
    "options[OPTION_USE_PRESOLVE] = DEFAULT_USE_PRESOLVE\n",
    "options[OPTION_USE_SPARSE_MATRIX] = DEFAULT_USE_SPARSE_MATRIX\n",
    "options[OPTION_USE_INTERIOR_POINT_METHOD] = DEFAULT_USE_INTERIOR_POINT_METHOD\n",
    "options[OPTION_VERBOSE] = DEFAULT_VERBOSE\n",
    "\n",
    "mps_string = MPS_EXAMPLE\n",
    "if !is_running_in_notebook()\n",
    "    parsed_args = parse_commandline()\n",
    "\n",
    "    # Process command-line name\n",
    "    if haskey(parsed_args, COMMAND_LINE_OPTION_FILENAME) && !isnothing(parsed_args[COMMAND_LINE_OPTION_FILENAME])\n",
    "        options[OPTION_FILENAME] = parsed_args[COMMAND_LINE_OPTION_FILENAME]\n",
    "        if isfile(options[OPTION_FILENAME])\n",
    "            mps_string = return open(read, options[OPTION_FILENAME])\n",
    "        else            \n",
    "            error(\"File not found or could not read: '$(options[OPTION_FILENAME])'\")\n",
    "        end\n",
    "    end    \n",
    "\n",
    "    if haskey(parsed_args, COMMAND_LINE_OPTION_USE_PRESOLVE) && !isnothing(parsed_args[COMMAND_LINE_OPTION_USE_PRESOLVE])\n",
    "        options[OPTION_USE_PRESOLVE] = parsed_args[COMMAND_LINE_OPTION_USE_PRESOLVE]\n",
    "    end\n",
    "    if haskey(parsed_args, COMMAND_LINE_OPTION_USE_SPARSE_MATRIX) && !isnothing(parsed_args[COMMAND_LINE_OPTION_USE_SPARSE_MATRIX])\n",
    "        options[OPTION_USE_SPARSE_MATRIX] = parsed_args[COMMAND_LINE_OPTION_USE_SPARSE_MATRIX]\n",
    "    end\n",
    "    if haskey(parsed_args, COMMAND_LINE_OPTION_USE_INTERIOR_POINT_METHOD) && !isnothing(parsed_args[COMMAND_LINE_OPTION_USE_INTERIOR_POINT_METHOD])\n",
    "        options[OPTION_USE_INTERIOR_POINT_METHOD] = parsed_args[COMMAND_LINE_OPTION_USE_INTERIOR_POINT_METHOD]\n",
    "    end\n",
    "    if haskey(parsed_args, COMMAND_LINE_OPTION_VERBOSE) && !isnothing(parsed_args[COMMAND_LINE_OPTION_VERBOSE])\n",
    "        options[OPTION_VERBOSE] = true\n",
    "    end\n",
    "end\n",
    "\n",
    "if options[OPTION_VERBOSE]\n",
    "    println(\"Options:\")\n",
    "    println(\"  Use presolve: $(options[OPTION_USE_PRESOLVE])\")\n",
    "    println(\"  Use sparse matrix: $(options[OPTION_USE_SPARSE_MATRIX])\")\n",
    "    println(\"  Use interior point method: $(options[OPTION_USE_INTERIOR_POINT_METHOD])\")\n",
    "    println(\"  Verbose output: $(options[OPTION_VERBOSE])\")\n",
    "end\n",
    "\n",
    "# Example usage\n",
    "lp = read_mps_from_string(mps_string)\n",
    "\n",
    "# Presolve the problem\n",
    "if options[\"use_presolve\"]\n",
    "    lp, fixed_vars, obj_adjust = presolve(lp)\n",
    "\n",
    "    println(\"\\nFixed variables:\")\n",
    "    for (var, val) in fixed_vars\n",
    "        println(\"$var = $val\")\n",
    "    end\n",
    "\n",
    "    println(\"\\nReduced problem:\")\n",
    "    println(\"Minimize: $(lp.is_minimize)\")\n",
    "    println(\"c = $(lp.c)\")\n",
    "    println(\"A = $(lp.A)\")\n",
    "    println(\"b = $(lp.b)\")\n",
    "    println(\"vars = $(lp.vars)\")\n",
    "    println(\"constraint_types = $(lp.constraint_types)\")\n",
    "\n",
    "end\n",
    "\n",
    "# solve the LP problem\n",
    "\n",
    "if options[\"use_interior_point_method\"]\n",
    "        println(\"\\nSolving the reduced problem using the Interior Point Method with dense matrices\")\n",
    "        execution_time = @elapsed x, obj_value = homogeneous_self_dual_ipm(lp)    \n",
    "else\n",
    "    if options[\"use_interior_point_method\"]\n",
    "        println(\"\\nSolving the reduced problem using the Revised Simplex Method with sparse matrices\")\n",
    "        execution_time = @elapsed x, obj_value = revised_simplex_sparse(lp)\n",
    "    else\n",
    "        println(\"\\nSolving the reduced problem using the Revised Simplex Method with dense matrices\")\n",
    "        execution_time = @elapsed x, obj_value = revised_simplex(lp)\n",
    "    end\n",
    "end\n",
    "println(\"\\nExecution time: $execution_time seconds\")\n",
    "\n",
    "# show the solution\n",
    "\n",
    "println(\"\\nFinal solution:\")\n",
    "for (var, val) in zip(lp.vars, x[1:length(lp.vars)])\n",
    "    println(\"$var = $(round(val, digits=6))\")\n",
    "end\n",
    "println(\"Objective value: $(round(obj_value, digits=6))\")\n",
    "\n",
    "# A = [3.0 1.0 -3.0 2.0 1.0;\n",
    "#         2.0 2.0 1.0 -1.0 2.0;\n",
    "#         1.0 -1.0 2.0 2.0 -3.0]\n",
    "# b = [9.0, 10.0, 11.0]\n",
    "# c = [-1.0, -7.0, -6.0, -3.0, -4.0]  # Negated for maximization\n",
    "# vars = [\"X3\", \"X4\", \"X5\", \"X2\", \"X1\"]\n",
    "# lp = LPProblem(false, c, A, b, vars, ['≤', '≤', '≤'])\n",
    "\n",
    "# x, obj_value = highs_inspired_ipm(lp)\n",
    "\n",
    "# println(\"\\nSolution:\")\n",
    "# for (var, val) in zip(lp.vars, x)\n",
    "#     println(\"$var = $val\")\n",
    "# end\n",
    "# println(\"Objective value: \", -obj_value)  # Negated back for maximization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
