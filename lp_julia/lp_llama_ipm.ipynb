{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Simple example of a Julia linear pogramming model\n",
    "#\n",
    "# Convert from notebook to julia program:\n",
    "#   python3 nb_to_jl.py lp_claude_revised_simplex.ipynb\n",
    "#\n",
    " \n",
    "using LinearAlgebra\n",
    "using SparseArrays\n",
    "using Random\n",
    "using ArgParse\n",
    "\n",
    "const DEFAULT_USE_PRESOLVE = false \n",
    "const DEFAULT_USE_INTERIOR_POINT_METHOD = true\n",
    "const DEFAULT_USE_SPARSE_MATRIX = false\n",
    "const DEFAULT_VERBOSE = true\n",
    "\n",
    "global options = Dict()\n",
    "\n",
    "const COMMAND_LINE_OPTION_FILENAME = \"filename\"\n",
    "const COMMAND_LINE_OPTION_USE_PRESOLVE = \"presolve\"\n",
    "const COMMAND_LINE_OPTION_USE_SPARSE_MATRIX = \"sparse\"\n",
    "const COMMAND_LINE_OPTION_USE_INTERIOR_POINT_METHOD = \"interior\"\n",
    "const COMMAND_LINE_OPTION_VERBOSE = \"verbose\"\n",
    "\n",
    "const OPTION_FILENAME = \"filename\"\n",
    "const OPTION_USE_PRESOLVE = \"use_presolve\"\n",
    "const OPTION_USE_SPARSE_MATRIX = \"use_sparse_matrix\"\n",
    "const OPTION_USE_INTERIOR_POINT_METHOD = \"use_interior_point_method\"\n",
    "const OPTION_VERBOSE = \"verbose\"\n",
    "\n",
    "# https://en.wikipedia.org/wiki/Revised_simplex_method\n",
    "const MPS_EXAMPLE::String = \"\"\"\n",
    "NAME          APPLIED_INTEGER_PROGRAMMING_9_7\n",
    "\n",
    "OBJSENSE\n",
    " MAX\n",
    "\n",
    "ROWS\n",
    " N  OBJ\n",
    " L  ROW1\n",
    " L  ROW2\n",
    " L  ROW3\n",
    "\n",
    "COLUMNS\n",
    "    X1        OBJ       4\n",
    "    X1        ROW1      1\n",
    "    X1        ROW2      2\n",
    "    X1        ROW3     -3\n",
    "    X2        OBJ       3\n",
    "    X2        ROW1      2\n",
    "    X2        ROW2     -1\n",
    "    X2        ROW3      2\n",
    "    X3        OBJ       1\n",
    "    X3        ROW1      3\n",
    "    X3        ROW2      2\n",
    "    X3        ROW3      1\n",
    "    X4        OBJ       7\n",
    "    X4        ROW1      1\n",
    "    X4        ROW2      2\n",
    "    X4        ROW3     -1\n",
    "    X5        OBJ       6\n",
    "    X5        ROW1     -3\n",
    "    X5        ROW2      1\n",
    "    X5        ROW3      2\n",
    "\n",
    "RHS\n",
    "    RHS1      ROW1      9\n",
    "    RHS1      ROW2     10\n",
    "    RHS1      ROW3     11\n",
    "\n",
    "BOUNDS\n",
    " LO BOUND1    X1        0\n",
    " LO BOUND1    X2        0\n",
    " LO BOUND1    X3        0\n",
    " LO BOUND1    X4        0\n",
    " LO BOUND1    X5        0\n",
    "\n",
    "ENDATA\n",
    "\"\"\"\n",
    "#=\n",
    "/opt/homebrew/Cellar/highs/1.7.2/bin/highs --solution_file ex97_highs.txt ex97.mps\n",
    "Running HiGHS 1.7.2 (git hash: n/a): Copyright (c) 2024 HiGHS under MIT licence terms\n",
    "LP   ex97 has 3 rows; 5 cols; 15 nonzeros\n",
    "Coefficient ranges:\n",
    "  Matrix [1e+00, 3e+00]\n",
    "  Cost   [1e+00, 7e+00]\n",
    "  Bound  [0e+00, 0e+00]\n",
    "  RHS    [9e+00, 1e+01]\n",
    "Presolving model\n",
    "3 rows, 5 cols, 15 nonzeros  0s\n",
    "3 rows, 5 cols, 15 nonzeros  0s\n",
    "Presolve : Reductions: rows 3(-0); columns 5(-0); elements 15(-0) - Not reduced\n",
    "Problem not reduced by presolve: solving the LP\n",
    "Using EKK dual simplex solver - serial\n",
    "  Iteration        Objective     Infeasibilities num(sum)\n",
    "          0    -2.0999978563e+01 Ph1: 3(11); Du: 5(21) 0s\n",
    "          4     9.4000000000e+01 Pr: 0(0) 0s\n",
    "Model   status      : Optimal\n",
    "Simplex   iterations: 4\n",
    "Objective value     :  9.4000000000e+01\n",
    "HiGHS run time      :          0.00\n",
    "\n",
    "Model status\n",
    "Optimal\n",
    "\n",
    "# Primal solution values\n",
    "Feasible\n",
    "Objective 94\n",
    "# Columns 5\n",
    "X1 7\n",
    "X2 10\n",
    "X3 0\n",
    "X4 0\n",
    "X5 6\n",
    "# Rows 3\n",
    "ROW1 9\n",
    "ROW2 10\n",
    "ROW3 11\n",
    "\n",
    "# Dual solution values\n",
    "Feasible\n",
    "# Columns 5\n",
    "X1 0\n",
    "X2 0\n",
    "X3 -16.4285714285714\n",
    "X4 -2.2380952380952\n",
    "X5 0\n",
    "# Rows 3\n",
    "ROW1 1.4761904761905\n",
    "ROW2 5.1904761904762\n",
    "ROW3 2.6190476190476\n",
    "\n",
    "# Basis\n",
    "HiGHS v1\n",
    "Valid\n",
    "# Columns 5\n",
    "1 1 0 0 1 \n",
    "# Rows 3\n",
    "2 2 2 \n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function is_running_in_notebook()\n",
    "    # Check if running in VS Code's Jupyter notebook environment\n",
    "    if (haskey(ENV, \"VSCODE_PID\") || haskey(ENV, \"VSCODE_CWD\"))\n",
    "        return true\n",
    "    # Check if running in a general Jupyter environment (including VS Code)\n",
    "    elseif isdefined(Main, :IJulia) && Main.IJulia.inited\n",
    "        return true\n",
    "    else\n",
    "        return false\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function parse_commandline()\n",
    "    s = ArgParseSettings()\n",
    "\n",
    "    @add_arg_table s begin\n",
    "        \"--filename\", \"-f\"\n",
    "            help = \"path to the problem file (mps format)\"\n",
    "            arg_type = String\n",
    "            required = true\n",
    "        \"--interior\", \"-i\"\n",
    "            help = \"use interior point method (LP only)\"\n",
    "            arg_type = Bool           \n",
    "        \"--min\"\n",
    "            help = \"minimization of the objective function\"\n",
    "            action = :store_true            \n",
    "        \"--max\"\n",
    "            help = \"maximization of the objective function\"\n",
    "            action = :store_true            \n",
    "        \"--presolve\"\n",
    "            help = \"use presolve (default true)\"\n",
    "            arg_type = Bool          \n",
    "        \"--simplex\"\n",
    "            help = \"use simplex method (default)\"\n",
    "            arg_type = Bool          \n",
    "        \"--sparse\", \"-s\"\n",
    "            help = \"use sparce matrix representation\"\n",
    "            arg_type = Bool\n",
    "        \"--verbose\", \"-v\"\n",
    "            help = \"verbose output\"\n",
    "            action = :store_true\n",
    "    end\n",
    "\n",
    "    return parse_args(s)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a struct to represent a Linear Programming problem\n",
    "struct LPProblem\n",
    "    is_minimize::Bool  # True if the objective is to minimize\n",
    "    c::Vector{Float64}  # Objective function coefficients\n",
    "    A::Matrix{Float64}  # Constraint matrix\n",
    "    b::Vector{Float64}  # Right-hand side of constraints\n",
    "    vars::Vector{String}  # Variable names\n",
    "    constraint_types::Vector{Char}  # Constraint types\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function read_mps_from_string(mps_string::String)\n",
    "    lines = split(mps_string, '\\n')\n",
    "    sections = Dict(\"NAME\" => \"\", \"ROWS\" => [], \"COLUMNS\" => Dict(), \"RHS\" => Dict(), \"BOUNDS\" => Dict())\n",
    "    current_section = \"\"\n",
    "    objective_name = \"\"\n",
    "    is_minimize = true\n",
    "\n",
    "    for line in lines\n",
    "        words = split(line)\n",
    "        (isempty(words) || (line[1] == '*')) && continue  # Skip empty lines and comments\n",
    "\n",
    "        if (line[1] != ' ') && words[1] in [\"NAME\", \"OBJSENSE\", \"ROWS\", \"COLUMNS\", \"RHS\", \"BOUNDS\", \"ENDATA\"]\n",
    "            current_section = words[1]\n",
    "            continue\n",
    "        end\n",
    "\n",
    "        if current_section == \"NAME\"\n",
    "            sections[\"NAME\"] = words[1]\n",
    "        elseif current_section == \"OBJSENSE\"\n",
    "            if words[1] == \"MAX\"\n",
    "                is_minimize = false\n",
    "            end\n",
    "        elseif current_section == \"ROWS\"\n",
    "            row_type, row_name = words\n",
    "            push!(sections[\"ROWS\"], (type=row_type, name=row_name))\n",
    "            if row_type == \"N\"\n",
    "                objective_name = row_name\n",
    "            end\n",
    "        elseif current_section == \"COLUMNS\"\n",
    "            col_name, row_name, value = words\n",
    "            value = parse(Float64, value)\n",
    "            if !haskey(sections[\"COLUMNS\"], col_name)\n",
    "                sections[\"COLUMNS\"][col_name] = Dict()\n",
    "            end\n",
    "            sections[\"COLUMNS\"][col_name][row_name] = value\n",
    "        elseif current_section == \"RHS\"\n",
    "            if length(words) == 3\n",
    "                _, row_name, value = words\n",
    "            else\n",
    "                row_name, value = words[2:3]\n",
    "            end\n",
    "            sections[\"RHS\"][row_name] = parse(Float64, value)\n",
    "        elseif current_section == \"BOUNDS\"\n",
    "            bound_type, _, var_name, value = words\n",
    "            if !haskey(sections[\"BOUNDS\"], var_name)\n",
    "                sections[\"BOUNDS\"][var_name] = Dict()\n",
    "            end\n",
    "            sections[\"BOUNDS\"][var_name][bound_type] = parse(Float64, value)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Convert to LPProblem structure\n",
    "    vars = collect(keys(sections[\"COLUMNS\"]))\n",
    "    n_vars = length(vars)\n",
    "    n_constraints = count(row -> row.type != \"N\", sections[\"ROWS\"])\n",
    "\n",
    "    c = zeros(n_vars)\n",
    "    A = zeros(n_constraints, n_vars)\n",
    "    b = zeros(n_constraints)\n",
    "    constraint_types = Char[]\n",
    "\n",
    "    # Populate objective function\n",
    "    for (i, var) in enumerate(vars)\n",
    "        if haskey(sections[\"COLUMNS\"][var], objective_name)\n",
    "            c[i] = sections[\"COLUMNS\"][var][objective_name]\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Populate constraint matrix and right-hand side\n",
    "    constraint_index = 0\n",
    "    for row in sections[\"ROWS\"]\n",
    "        if row.type != \"N\"\n",
    "            constraint_index += 1\n",
    "            push!(constraint_types, row.type[1])  # Store constraint type\n",
    "            for (i, var) in enumerate(vars)\n",
    "                if haskey(sections[\"COLUMNS\"][var], row.name)\n",
    "                    A[constraint_index, i] = sections[\"COLUMNS\"][var][row.name]\n",
    "                end\n",
    "            end\n",
    "            b[constraint_index] = get(sections[\"RHS\"], row.name, 0.0)\n",
    "            \n",
    "            # Adjust for 'G' type constraints\n",
    "            if row.type == \"G\"\n",
    "                A[constraint_index, :] *= -1\n",
    "                b[constraint_index] *= -1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Process bound constraints\n",
    "    lb = fill(-Inf, n_vars)\n",
    "    ub = fill(Inf, n_vars)\n",
    "    for (i, var) in enumerate(vars)\n",
    "        if haskey(sections[\"BOUNDS\"], var)\n",
    "            bounds = sections[\"BOUNDS\"][var]\n",
    "            if haskey(bounds, \"LO\")\n",
    "                lb[i] = bounds[\"LO\"]\n",
    "            end\n",
    "            if haskey(bounds, \"UP\")\n",
    "                ub[i] = bounds[\"UP\"]\n",
    "            end\n",
    "            if haskey(bounds, \"FX\")\n",
    "                lb[i] = ub[i] = bounds[\"FX\"]\n",
    "            end\n",
    "        else\n",
    "            lb[i] = 0.0  # Default lower bound is 0 if not specified\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Add bound constraints to A and b\n",
    "    n_bound_constraints = count(x -> x > -Inf, lb) + count(x -> x < Inf, ub)\n",
    "    A_with_bounds = zeros(n_constraints + n_bound_constraints, n_vars)\n",
    "    b_with_bounds = zeros(n_constraints + n_bound_constraints)\n",
    "    \n",
    "    A_with_bounds[1:n_constraints, :] = A\n",
    "    b_with_bounds[1:n_constraints] = b\n",
    "    \n",
    "    bound_constraint_index = n_constraints\n",
    "    for i in 1:n_vars\n",
    "        if lb[i] > -Inf\n",
    "            bound_constraint_index += 1\n",
    "            A_with_bounds[bound_constraint_index, i] = 1\n",
    "            b_with_bounds[bound_constraint_index] = lb[i]\n",
    "            push!(constraint_types, 'G')\n",
    "        end\n",
    "        if ub[i] < Inf\n",
    "            bound_constraint_index += 1\n",
    "            A_with_bounds[bound_constraint_index, i] = 1\n",
    "            b_with_bounds[bound_constraint_index] = ub[i]\n",
    "            push!(constraint_types, 'L')\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return LPProblem(is_minimize, c, A_with_bounds, b_with_bounds, vars, constraint_types)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function presolve(lp::LPProblem; eps::Float64=1e-8)\n",
    "    is_minimize, c, A, b = lp.is_minimize, lp.c, sparse(lp.A), lp.b\n",
    "    vars, constraint_types = lp.vars, lp.constraint_types\n",
    "    m, n = size(A)\n",
    "\n",
    "    # Initialize masks for rows and columns to keep\n",
    "    keep_rows = trues(m)\n",
    "    keep_cols = trues(n)\n",
    "\n",
    "    # Step 1: Remove zero columns\n",
    "    for j in 1:n\n",
    "        if nnz(A[:, j]) == 0 && abs(c[j]) < eps\n",
    "            keep_cols[j] = false\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Step 2: Remove zero rows\n",
    "    for i in 1:m\n",
    "        if nnz(A[i, :]) == 0\n",
    "            if abs(b[i]) < eps\n",
    "                keep_rows[i] = false\n",
    "            else\n",
    "                error(\"Infeasible problem: zero row with non-zero RHS\")\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Step 3: Remove duplicate rows\n",
    "    for i in 1:m\n",
    "        if !keep_rows[i]\n",
    "            continue\n",
    "        end\n",
    "        for j in (i+1):m\n",
    "            if !keep_rows[j]\n",
    "                continue\n",
    "            end\n",
    "            if A[i, :] ≈ A[j, :] && abs(b[i] - b[j]) < eps && constraint_types[i] == constraint_types[j]\n",
    "                keep_rows[j] = false\n",
    "            elseif A[i, :] ≈ -A[j, :] && abs(b[i] + b[j]) < eps && \n",
    "                   ((constraint_types[i] == '≤' && constraint_types[j] == '≥') || \n",
    "                    (constraint_types[i] == '≥' && constraint_types[j] == '≤'))\n",
    "                keep_rows[j] = false\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Step 4: Fix variables and tighten bounds\n",
    "    fixed_vars = Dict{String, Float64}()\n",
    "    for j in 1:n\n",
    "        col = A[:, j]\n",
    "        if nnz(col) == 1\n",
    "            i = findfirst(!iszero, col)\n",
    "            if abs(col[i]) ≈ 1 && constraint_types[i] == '='\n",
    "                val = b[i] / col[i]\n",
    "                fixed_vars[vars[j]] = val\n",
    "                keep_cols[j] = false\n",
    "                b .-= val * col\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Apply the reductions\n",
    "    A_new = A[keep_rows, keep_cols]\n",
    "    b_new = b[keep_rows]\n",
    "    c_new = c[keep_cols]\n",
    "    vars_new = vars[keep_cols]\n",
    "    constraint_types_new = constraint_types[keep_rows]\n",
    "\n",
    "    # Adjust the objective for fixed variables\n",
    "    obj_adjust = isempty(fixed_vars) ? 0.0 : sum(c[j] * val for (j, val) in enumerate(lp.vars) if haskey(fixed_vars, val))\n",
    "\n",
    "    if options[OPTION_VERBOSE]\n",
    "        println(\"\\nPresolve summary:\")\n",
    "        println(\"  Original problem size: $(m) x $(n)\")\n",
    "        println(\"  Reduced problem size: $(sum(keep_rows)) x $(sum(keep_cols))\")\n",
    "        println(\"  Number of fixed variables: $(length(fixed_vars))\")\n",
    "        println(\"  Objective adjustment: $obj_adjust\")\n",
    "    end\n",
    "\n",
    "    return LPProblem(is_minimize, c_new, Matrix(A_new), b_new, vars_new, constraint_types_new), fixed_vars, obj_adjust\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=\n",
    "Theoretical basis for each step:\n",
    "\n",
    "Problem Formulation:\n",
    "\n",
    "The Revised Simplex Method solves linear programming problems in the standard form:\n",
    "Maximize c^T x\n",
    "Subject to Ax = b\n",
    "x ≥ 0\n",
    "\n",
    "\n",
    "Slack Variables (Step 0):\n",
    "\n",
    "Slack variables are added to convert inequality constraints to equality constraints.\n",
    "This ensures that the problem is in standard form for the simplex method.\n",
    "\n",
    "\n",
    "Basic and Non-Basic Variables:\n",
    "\n",
    "The method partitions variables into basic (B) and non-basic (N) variables.\n",
    "Initially, slack variables form the basis, corresponding to the identity matrix in the augmented constraint matrix.\n",
    "\n",
    "\n",
    "Revised Simplex Iteration:\n",
    "a. Basic Solution (Step 1):\n",
    "\n",
    "Compute x_B = B^(-1) * b, where B is the basis matrix.\n",
    "This gives the values of basic variables in the current solution.\n",
    "\n",
    "b. Reduced Costs (Step 2):\n",
    "\n",
    "Compute y = c_B' * B^(-1), where c_B are the objective coefficients of basic variables.\n",
    "Calculate reduced costs: c_N - y' * A_N, where A_N are columns of non-basic variables.\n",
    "Reduced costs measure the rate of change in the objective for unit increase in non-basic variables.\n",
    "\n",
    "c. Optimality Check (Step 3):\n",
    "\n",
    "If all reduced costs are non-positive, the current solution is optimal.\n",
    "This is based on the theorem that a basic feasible solution is optimal if and only if all reduced costs are non-positive.\n",
    "\n",
    "d. Entering Variable (Step 4):\n",
    "\n",
    "Choose the non-basic variable with the most positive reduced cost to enter the basis.\n",
    "This variable has the potential to improve the objective value the most.\n",
    "\n",
    "e. Direction Computation (Step 5):\n",
    "\n",
    "Compute d = B^(-1) * A_q, where A_q is the column of the entering variable.\n",
    "This determines how basic variables change as the entering variable increases.\n",
    "\n",
    "f. Unboundedness Check (Step 6):\n",
    "\n",
    "If all elements of d are non-positive and the reduced cost is positive, the problem is unbounded.\n",
    "This means we can increase the entering variable indefinitely, improving the objective without bound.\n",
    "\n",
    "g. Leaving Variable (Step 7):\n",
    "\n",
    "Perform the minimum ratio test: min(x_B_i / d_i) for d_i > 0.\n",
    "This determines how far we can move along the edge without violating non-negativity constraints.\n",
    "\n",
    "h. Basis Update (Step 8):\n",
    "\n",
    "Swap the entering and leaving variables in the basis.\n",
    "This moves to an adjacent extreme point of the feasible region.\n",
    "\n",
    "\n",
    "Convergence:\n",
    "\n",
    "The algorithm repeats these steps until optimality is reached or unboundedness is detected.\n",
    "Each iteration either improves the objective value or determines that the problem is unbounded.\n",
    "For non-degenerate problems, the algorithm is guaranteed to terminate in a finite number of steps.\n",
    "\n",
    "\n",
    "Numerical Considerations:\n",
    "\n",
    "Small tolerance (1e-10) is used for numerical stability in comparisons.\n",
    "A maximum iteration limit prevents infinite loops in case of cycling (rare in practice, but possible in degenerate problems).\n",
    "\n",
    "This implementation of the Revised Simplex Method efficiently solves linear programming problems by working with the inverse of the basis matrix and reduced costs, rather than maintaining the entire tableau as in the standard Simplex Method.\n",
    "=#\n",
    "\n",
    "function revised_simplex(lp::LPProblem)\n",
    "    c, A, b = lp.c, lp.A, lp.b\n",
    "    m, n = size(A)\n",
    "    \n",
    "    # If minimizing, negate the objective function to convert to a maximization problem\n",
    "    if lp.is_minimize\n",
    "        c = -c\n",
    "    end\n",
    "    \n",
    "    println(\"\\nInitial problem:\")\n",
    "    println(\"  Objective function coefficients c: \", lp.c)\n",
    "    println(\"  Constraint matrix A: \", lp.A)\n",
    "    println(\"  Right-hand side b: \", lp.b)\n",
    "    println(\"  Variables: \", lp.vars) \n",
    "    println(\"  Optimization type: \", lp.is_minimize ? \"Minimize\" : \"Maximize\")\n",
    "    \n",
    "    # Step 0: Add slack variables to convert inequalities to equalities\n",
    "    A = [A I(m)]  # Augment A with identity matrix for slack variables\n",
    "    c = [c; zeros(m)]  # Extend objective coefficients with zeros for slack variables\n",
    "    n = n + m  # Update number of variables\n",
    "    \n",
    "    # Initialize basis with slack variables\n",
    "    B = collect(n-m+1:n)  # Indices of basic variables\n",
    "    N = collect(1:n-m)    # Indices of non-basic variables\n",
    "    \n",
    "    println(\"  Initial basis: \", B)\n",
    "    println(\"  Initial non-basic variables: \", N)\n",
    "    \n",
    "    iteration = 0\n",
    "    while true\n",
    "        iteration += 1\n",
    "        println(\"\\nIteration \", iteration)\n",
    "        \n",
    "        # Step 1: Compute basic solution\n",
    "        B_matrix = A[:, B]  # Extract basis matrix\n",
    "        x_B = B_matrix \\ b  # Solve B * x_B = b for basic variables\n",
    "        \n",
    "        println(\"  Basic solution: \", x_B)\n",
    "        \n",
    "        # Step 2: Compute reduced costs\n",
    "        y = (c[B]' / B_matrix)'  # Compute dual variables: y' * B = c_B'\n",
    "        c_N = c[N] - A[:, N]' * y  # Compute reduced costs for non-basic variables\n",
    "        \n",
    "        println(\"  Reduced costs: \", c_N)\n",
    "        \n",
    "        # Step 3: Check optimality\n",
    "        if all(c_N .<= 1e-10)  # If all reduced costs are non-positive, solution is optimal\n",
    "            x = zeros(n)\n",
    "            x[B] = x_B\n",
    "            println(\"  Optimal solution found\")\n",
    "            obj_value = dot(c[1:length(lp.vars)], x[1:length(lp.vars)])\n",
    "            if lp.is_minimize\n",
    "                obj_value = -obj_value  # Convert back to minimization objective\n",
    "            end\n",
    "            return x[1:length(lp.vars)], obj_value\n",
    "        end\n",
    "        \n",
    "        # Step 4: Choose entering variable (most positive reduced cost)\n",
    "        e = argmax(c_N)\n",
    "        q = N[e]\n",
    "        \n",
    "        println(\"  Entering variable: \", q)\n",
    "        \n",
    "        # Step 5: Compute direction of edge to traverse\n",
    "        d = B_matrix \\ A[:, q]\n",
    "        \n",
    "        println(\"  Direction: \", d)\n",
    "        \n",
    "        # Step 6: Check unboundedness\n",
    "        if all(d .<= 1e-10)  # If direction is non-positive, problem is unbounded\n",
    "            error(\"  Problem is unbounded\")\n",
    "        end\n",
    "        \n",
    "        # Step 7: Choose leaving variable (minimum ratio test)\n",
    "        ratios = x_B ./ d\n",
    "        ratios[d .<= 1e-10] .= Inf  # Avoid division by zero or negative values\n",
    "        l = argmin(filter(x -> x > 0, ratios))\n",
    "        \n",
    "        p = B[l]\n",
    "        println(\"  Leaving variable: \", p)\n",
    "        \n",
    "        # Step 8: Update basis\n",
    "        B[l] = q\n",
    "        N[e] = p\n",
    "        \n",
    "        println(\"  New basis: \", B)\n",
    "        println(\"  New non-basic variables: \", N)\n",
    "        \n",
    "        # Safeguard against infinite loops\n",
    "        if iteration > 100\n",
    "            println(\"  Maximum iterations reached\")\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    error(\"Algorithm did not converge\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function revised_simplex_sparse(lp::LPProblem)\n",
    "    c, A, b = lp.c, sparse(lp.A), lp.b\n",
    "    m, n = size(A)\n",
    "    \n",
    "    # If minimizing, negate the objective function to convert to a maximization problem\n",
    "    if lp.is_minimize\n",
    "        c = -c\n",
    "    end\n",
    "    \n",
    "    println(\"\\nInitial problem:\")\n",
    "    println(\"  Objective function coefficients c: \", lp.c)\n",
    "    println(\"  Constraint matrix A: \", lp.A)\n",
    "    println(\"  Right-hand side b: \", lp.b)\n",
    "    println(\"  Variables: \", lp.vars)\n",
    "    println(\"  Optimization type: \", lp.is_minimize ? \"Minimize\" : \"Maximize\")\n",
    "    \n",
    "    # Step 0: Add slack variables to convert inequalities to equalities\n",
    "    A = [A sparse(I, m, m)]  # Augment A with sparse identity matrix for slack variables\n",
    "    c = [c; zeros(m)]  # Extend objective coefficients with zeros for slack variables\n",
    "    n = n + m  # Update number of variables\n",
    "    \n",
    "    # Initialize basis with slack variables\n",
    "    B = collect(n-m+1:n)  # Indices of basic variables\n",
    "    N = collect(1:n-m)    # Indices of non-basic variables\n",
    "    \n",
    "    println(\"  Initial basis: \", B)\n",
    "    println(\"  Initial non-basic variables: \", N)\n",
    "    \n",
    "    iteration = 0\n",
    "    while true\n",
    "        iteration += 1\n",
    "        println(\"\\nIteration \", iteration)\n",
    "        \n",
    "        # Step 1: Compute basic solution\n",
    "        B_matrix = A[:, B]  # Extract basis matrix\n",
    "        x_B = B_matrix \\ Vector(b)  # Solve B * x_B = b for basic variables\n",
    "        \n",
    "        println(\"  Basic solution: \", x_B)\n",
    "        \n",
    "        # Step 2: Compute reduced costs\n",
    "        y = (Vector(c[B])' / B_matrix)'  # Compute dual variables: y' * B = c_B'\n",
    "        c_N = c[N] - A[:, N]' * y  # Compute reduced costs for non-basic variables\n",
    "        \n",
    "        println(\"  Reduced costs: \", c_N)\n",
    "        \n",
    "        # Step 3: Check optimality\n",
    "        if all(c_N .<= 1e-10)  # If all reduced costs are non-positive, solution is optimal\n",
    "            x = spzeros(n)\n",
    "            x[B] = x_B\n",
    "            println(\"  Optimal solution found\")\n",
    "            obj_value = dot(c[1:length(lp.vars)], x[1:length(lp.vars)])\n",
    "            if lp.is_minimize\n",
    "                obj_value = -obj_value  # Convert back to minimization objective\n",
    "            end\n",
    "            return Array(x[1:length(lp.vars)]), obj_value\n",
    "        end\n",
    "        \n",
    "        # Step 4: Choose entering variable (most positive reduced cost)\n",
    "        e = argmax(c_N)\n",
    "        q = N[e]\n",
    "        \n",
    "        println(\"  Entering variable: \", q)\n",
    "        \n",
    "        # Step 5: Compute direction of edge to traverse\n",
    "        d = B_matrix \\ Vector(A[:, q])  # Convert sparse column to dense vector\n",
    "        \n",
    "        println(\"  Direction: \", d)\n",
    "        \n",
    "        # Step 6: Check unboundedness\n",
    "        if all(d .<= 1e-10)  # If direction is non-positive, problem is unbounded\n",
    "            error(\"  Problem is unbounded\")\n",
    "        end\n",
    "        \n",
    "        # Step 7: Choose leaving variable (minimum ratio test)\n",
    "        ratios = x_B ./ d\n",
    "        ratios[d .<= 1e-10] .= Inf  # Avoid division by zero or negative values\n",
    "        l = argmin(filter(x -> x > 0, ratios))\n",
    "        \n",
    "        p = B[l]\n",
    "        println(\"  Leaving variable: \", p)\n",
    "        \n",
    "        # Step 8: Update basis\n",
    "        B[l] = q\n",
    "        N[e] = p\n",
    "        \n",
    "        println(\"  New basis: \", B)\n",
    "        println(\"  New non-basic variables: \", N)\n",
    "        \n",
    "        # Safeguard against infinite loops\n",
    "        if iteration > 100\n",
    "            println(\"  Maximum iterations reached\")\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    error(\"Algorithm did not converge\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function corrector_direction(A, r_b, r_s, x, s, Δx_aff, Δy_aff)\n",
    "    println(\"Computing corrector direction:\")\n",
    "    \n",
    "    # Get dimensions\n",
    "    m, n = size(A)\n",
    "    println(\"  m: $m, n: $n\")\n",
    "\n",
    "    # Dimension checks\n",
    "    if size(A, 1) != m || size(A, 2) != n\n",
    "        error(\"A should be an m×n matrix. Got size(A) = $(size(A))\")\n",
    "    end\n",
    "    if length(r_b) != m || length(r_s) != m || length(s) != m || length(Δy_aff) != m\n",
    "        error(\"r_b, r_s, s, and Δy_aff should be m-dimensional vectors. \n",
    "               Got lengths: r_b ($(length(r_b))), r_s ($(length(r_s))), \n",
    "               s ($(length(s))), Δy_aff ($(length(Δy_aff)))\")\n",
    "    end\n",
    "    if length(x) != n || length(Δx_aff) != n\n",
    "        error(\"x and Δx_aff should be n-dimensional vectors. \n",
    "               Got lengths: x ($(length(x))), Δx_aff ($(length(Δx_aff)))\")\n",
    "    end\n",
    "\n",
    "    # Ensure vectors are column vectors\n",
    "    r_b = vec(r_b)\n",
    "    r_s = vec(r_s)\n",
    "    x = vec(x)\n",
    "    s = vec(s)\n",
    "    Δx_aff = vec(Δx_aff)\n",
    "    Δy_aff = vec(Δy_aff)\n",
    "\n",
    "    println(\"  A: $A\")\n",
    "    println(\"  r_b: $r_b\")\n",
    "    println(\"  r_s: $r_s\")\n",
    "    println(\"  x: $x\")\n",
    "    println(\"  s: $s\")\n",
    "    println(\"  Δx_aff: $Δx_aff\")\n",
    "    println(\"  Δy_aff: $Δy_aff\")\n",
    "\n",
    "    # Compute Δs_aff\n",
    "    Δs_aff = r_s - A * Δx_aff\n",
    "\n",
    "    # Compute μ (barrier parameter)\n",
    "    μ = (dot(x, A' * s) / n) * ((s + Δs_aff)' * (A * (x + Δx_aff)) / (s' * (A * x)))^3\n",
    "\n",
    "    # Compute K matrix\n",
    "    K = [spdiagm(0 => s) A; A' -spdiagm(0 => x)]\n",
    "    println(\"  K: $K\")\n",
    "\n",
    "    # Compute rhs vector\n",
    "    rhs = [r_b - A * Δx_aff;\n",
    "           A' * r_s - A' * Δs_aff - (x .* (A' * Δs_aff) + A' * s .* Δx_aff - μ * ones(n))]\n",
    "    println(\"  rhs: $rhs\")\n",
    "\n",
    "    # Solve system\n",
    "    direction = K \\ rhs\n",
    "    println(\"  direction: $direction\")\n",
    "\n",
    "    # Extract and return the components of the direction\n",
    "    Δy_cor = direction[1:m]\n",
    "    Δx_cor = direction[m+1:end]\n",
    "\n",
    "    return Δx_cor, Δy_cor\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function affine_scaling_direction(A, r_b, r_s, x, s, y, r_c)\n",
    "    println(\"Computing affine scaling direction:\")\n",
    "    println(\"  A: $A\")\n",
    "    println(\"  r_b: $r_b\")\n",
    "    println(\"  r_s: $r_s\")\n",
    "    println(\"  x: $x\")\n",
    "    println(\"  s: $s\")\n",
    "\n",
    "    m, n = size(A)\n",
    "    println(\"  m: $m, n: $n\")\n",
    "\n",
    "    # Ensure vectors are column vectors\n",
    "    r_b = vec(r_b)\n",
    "    r_s = vec(r_s)\n",
    "    x = vec(x)\n",
    "    s = vec(s)\n",
    "    y = vec(y)\n",
    "    r_c = vec(r_c)\n",
    "\n",
    "    # Compute K matrix\n",
    "    K = [spdiagm(0 => s) A; A' -spdiagm(0 => x)]\n",
    "    println(\"  K: $K\")\n",
    "\n",
    "    # Compute rhs vector\n",
    "    rhs = [r_b; -(A' * y + r_c)]\n",
    "    println(\"  rhs: $rhs\")\n",
    "\n",
    "    # Solve system\n",
    "    direction = K \\ rhs\n",
    "    println(\"  direction: $direction\")\n",
    "\n",
    "    # Extract and return the components of the direction\n",
    "    Δy = direction[1:m]\n",
    "    Δx = direction[m+1:end]\n",
    "\n",
    "    return Δx, Δy\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function convert_inequality_constraints(A, b, constraint_types)\n",
    "    m, n = size(A)\n",
    "    println(\"Original A: $A\")\n",
    "    println(\"Original b: $b\")\n",
    "    println(\"Original constraint_types: $constraint_types\")\n",
    "\n",
    "    new_A = Matrix{Float64}(undef, 0, n)  # Initialize with correct number of columns\n",
    "    new_b = Float64[]  # Initialize as empty vector\n",
    "    new_constraint_types = Char[]\n",
    "\n",
    "    for i = 1:m\n",
    "        println(\"Processing constraint $i:\")\n",
    "        println(\"  A[i, :]: $(A[i, :])\")\n",
    "        println(\"  b[i]: $(b[i])\")\n",
    "        println(\"  constraint_types[i]: $(constraint_types[i])\")\n",
    "\n",
    "        if constraint_types[i] == 'L'\n",
    "            println(\"  Constraint type: Less than or equal to\")\n",
    "            new_A = vcat(new_A, A[i, :]')  # Transpose A[i, :] to make it a row vector\n",
    "            push!(new_b, b[i])\n",
    "            push!(new_constraint_types, 'E')\n",
    "        elseif constraint_types[i] == 'G'\n",
    "            println(\"  Constraint type: Greater than or equal to\")\n",
    "            new_A = vcat(new_A, -A[i, :]')  # Transpose -A[i, :] to make it a row vector\n",
    "            push!(new_b, -b[i])\n",
    "            push!(new_constraint_types, 'E')\n",
    "        elseif constraint_types[i] == 'E'\n",
    "            println(\"  Constraint type: Equal to\")\n",
    "            new_A = vcat(new_A, A[i, :]')  # Transpose A[i, :] to make it a row vector\n",
    "            push!(new_b, b[i])\n",
    "            push!(new_constraint_types, 'E')\n",
    "        end\n",
    "    end\n",
    "\n",
    "    println(\"Converted A: $new_A\")\n",
    "    println(\"Converted b: $new_b\")\n",
    "    println(\"Converted constraint_types: $new_constraint_types\")\n",
    "\n",
    "    return new_A, new_b, new_constraint_types\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function compute_step_length(v, Δv)\n",
    "    α = 1.0\n",
    "    for i in eachindex(v)\n",
    "        if Δv[i] < 0\n",
    "            α = min(α, -v[i] / Δv[i])\n",
    "        end\n",
    "    end\n",
    "    return α\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=\n",
    "The rest of the Interior Point Method implementation looks correct. The main loop in the interior_point_method function follows the standard steps:\n",
    "\n",
    "Compute residuals\n",
    "Compute affine scaling direction\n",
    "Compute corrector direction\n",
    "Combine directions and update variables\n",
    "Update barrier parameter\n",
    "Check for convergence\n",
    "\n",
    "The method also includes proper logging and debugging output, which is helpful for understanding the algorithm's progress.\n",
    "To further improve the code, you might consider:\n",
    "\n",
    "Adding error handling for cases where the problem doesn't converge within the maximum number of iterations.\n",
    "Implementing a dynamic update strategy for the barrier parameter μ.\n",
    "Adding more sophisticated step length calculations to ensure variables remain positive.\n",
    "=#\n",
    "\n",
    "\n",
    "function interior_point_method(lp::LPProblem; \n",
    "                               tolerance=1e-8, \n",
    "                               max_iterations=1000, \n",
    "                               barrier_parameter=0.1)\n",
    "    # Initialize variables\n",
    "    n = length(lp.vars)\n",
    "    m = size(lp.A, 1)\n",
    "    x = ones(n)\n",
    "    s = ones(m)\n",
    "    y = zeros(m)\n",
    "    μ = barrier_parameter\n",
    "    iteration = 0\n",
    "\n",
    "    println(\"Starting IPM solver with parameters:\")\n",
    "    println(\"  Tolerance: $tolerance\")\n",
    "    println(\"  Max iterations: $max_iterations\")\n",
    "    println(\"  Barrier parameter: $barrier_parameter\")\n",
    "\n",
    "    # Convert inequality constraints to standard form\n",
    "    A, b, constraint_types = convert_inequality_constraints(lp.A, lp.b, lp.constraint_types)\n",
    "    println(\"Converted inequality constraints to standard form:\")\n",
    "    println(\"  A: $A\")\n",
    "    println(\"  b: $b\")\n",
    "    println(\"  constraint_types: $constraint_types\")\n",
    "\n",
    "    # Main loop\n",
    "    while iteration < max_iterations\n",
    "        println(\"Iteration $iteration:\")\n",
    "\n",
    "        # Compute residuals\n",
    "        r_c = lp.c - A' * y\n",
    "        r_b = b - A * x\n",
    "        r_s = s - (A * x - b)\n",
    "        println(\"  Residuals:\")\n",
    "        println(\"    r_c: $r_c\")\n",
    "        println(\"    r_b: $r_b\")\n",
    "        println(\"    r_s: $r_s\")\n",
    "\n",
    "        # Compute affine scaling direction\n",
    "        Δx_aff, Δy_aff = affine_scaling_direction(A, r_b, r_s, x, s, y, r_c)\n",
    "        Δs_aff = r_s - A * Δx_aff\n",
    "        println(\"  Affine scaling direction:\")\n",
    "        println(\"    Δx_aff: $Δx_aff\")\n",
    "        println(\"    Δs_aff: $Δs_aff\")\n",
    "        println(\"    Δy_aff: $Δy_aff\")\n",
    "\n",
    "        # Compute corrector direction\n",
    "        Δx_cor, Δy_cor = corrector_direction(A, r_b, r_s, x, s, Δx_aff, Δy_aff)\n",
    "        Δs_cor = r_s - A * Δx_cor\n",
    "        println(\"  Corrector direction:\")\n",
    "        println(\"    Δx_cor: $Δx_cor\")\n",
    "        println(\"    Δs_cor: $Δs_cor\")\n",
    "        println(\"    Δy_cor: $Δy_cor\")\n",
    "\n",
    "        # Combine directions and update variables\n",
    "        Δx = Δx_aff + Δx_cor\n",
    "        Δs = Δs_aff + Δs_cor\n",
    "        Δy = Δy_aff + Δy_cor\n",
    "\n",
    "        # Compute step length\n",
    "        α_pri = compute_step_length(x, Δx)\n",
    "        α_dual = compute_step_length(s, Δs)\n",
    "        α = min(0.99 * min(α_pri, α_dual), 1)\n",
    "\n",
    "        x += α * Δx\n",
    "        s += α * Δs\n",
    "        y += α * Δy\n",
    "        println(\"  Updated variables:\")\n",
    "        println(\"    x: $x\")\n",
    "        println(\"    s: $s\")\n",
    "        println(\"    y: $y\")\n",
    "\n",
    "        # Update barrier parameter\n",
    "        μ = (x' * s) / n\n",
    "        println(\"  Updated barrier parameter: $μ\")\n",
    "\n",
    "        # Check convergence\n",
    "        if norm([r_c; r_b; r_s]) < tolerance && μ < tolerance\n",
    "            println(\"Converged in $iteration iterations\")\n",
    "            break\n",
    "        end\n",
    "\n",
    "        iteration += 1\n",
    "    end\n",
    "\n",
    "    return x, y, iteration\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main program\n",
    "\n",
    "if is_running_in_notebook()\n",
    "    println(\"Running as a notebook\")    \n",
    "else\n",
    "    println(\"Running as a script\")\n",
    "end\n",
    "\n",
    "options[OPTION_USE_PRESOLVE] = DEFAULT_USE_PRESOLVE\n",
    "options[OPTION_USE_SPARSE_MATRIX] = DEFAULT_USE_SPARSE_MATRIX\n",
    "options[OPTION_USE_INTERIOR_POINT_METHOD] = DEFAULT_USE_INTERIOR_POINT_METHOD\n",
    "options[OPTION_VERBOSE] = DEFAULT_VERBOSE\n",
    "\n",
    "mps_string = MPS_EXAMPLE\n",
    "if !is_running_in_notebook()\n",
    "    parsed_args = parse_commandline()\n",
    "\n",
    "    # Process command-line name\n",
    "    if haskey(parsed_args, COMMAND_LINE_OPTION_FILENAME) && !isnothing(parsed_args[COMMAND_LINE_OPTION_FILENAME])\n",
    "        options[OPTION_FILENAME] = parsed_args[COMMAND_LINE_OPTION_FILENAME]\n",
    "        if isfile(options[OPTION_FILENAME])\n",
    "            mps_string = return open(read, options[OPTION_FILENAME])\n",
    "        else            \n",
    "            error(\"File not found or could not read: '$(options[OPTION_FILENAME])'\")\n",
    "        end\n",
    "    end    \n",
    "\n",
    "    if haskey(parsed_args, COMMAND_LINE_OPTION_USE_PRESOLVE) && !isnothing(parsed_args[COMMAND_LINE_OPTION_USE_PRESOLVE])\n",
    "        options[OPTION_USE_PRESOLVE] = parsed_args[COMMAND_LINE_OPTION_USE_PRESOLVE]\n",
    "    end\n",
    "    if haskey(parsed_args, COMMAND_LINE_OPTION_USE_SPARSE_MATRIX) && !isnothing(parsed_args[COMMAND_LINE_OPTION_USE_SPARSE_MATRIX])\n",
    "        options[OPTION_USE_SPARSE_MATRIX] = parsed_args[COMMAND_LINE_OPTION_USE_SPARSE_MATRIX]\n",
    "    end\n",
    "    if haskey(parsed_args, COMMAND_LINE_OPTION_USE_INTERIOR_POINT_METHOD) && !isnothing(parsed_args[COMMAND_LINE_OPTION_USE_INTERIOR_POINT_METHOD])\n",
    "        options[OPTION_USE_INTERIOR_POINT_METHOD] = parsed_args[COMMAND_LINE_OPTION_USE_INTERIOR_POINT_METHOD]\n",
    "    end\n",
    "    if haskey(parsed_args, COMMAND_LINE_OPTION_VERBOSE) && !isnothing(parsed_args[COMMAND_LINE_OPTION_VERBOSE])\n",
    "        options[OPTION_VERBOSE] = true\n",
    "    end\n",
    "end\n",
    "\n",
    "if options[OPTION_VERBOSE]\n",
    "    println(\"Options:\")\n",
    "    println(\"  Use presolve: $(options[OPTION_USE_PRESOLVE])\")\n",
    "    println(\"  Use sparse matrix: $(options[OPTION_USE_SPARSE_MATRIX])\")\n",
    "    println(\"  Use interior point method: $(options[OPTION_USE_INTERIOR_POINT_METHOD])\")\n",
    "    println(\"  Verbose output: $(options[OPTION_VERBOSE])\")\n",
    "end\n",
    "\n",
    "# Example usage\n",
    "lp = read_mps_from_string(mps_string)\n",
    "\n",
    "# Presolve the problem\n",
    "if options[\"use_presolve\"]\n",
    "    lp, fixed_vars, obj_adjust = presolve(lp)\n",
    "\n",
    "    println(\"\\nFixed variables:\")\n",
    "    for (var, val) in fixed_vars\n",
    "        println(\"$var = $val\")\n",
    "    end\n",
    "\n",
    "    println(\"\\nReduced problem:\")\n",
    "    println(\"Minimize: $(lp.is_minimize)\")\n",
    "    println(\"c = $(lp.c)\")\n",
    "    println(\"A = $(lp.A)\")\n",
    "    println(\"b = $(lp.b)\")\n",
    "    println(\"vars = $(lp.vars)\")\n",
    "    println(\"constraint_types = $(lp.constraint_types)\")\n",
    "\n",
    "end\n",
    "\n",
    "# solve the LP problem\n",
    "\n",
    "if options[\"use_interior_point_method\"]\n",
    "        println(\"\\nSolving the reduced problem using the Interior Point Method with dense matrices\")\n",
    "        execution_time = @elapsed x, y, iterations = interior_point_method(lp) \n",
    "else\n",
    "    if options[\"use_interior_point_method\"]\n",
    "        println(\"\\nSolving the reduced problem using the Revised Simplex Method with sparse matrices\")\n",
    "        execution_time = @elapsed x, obj_value = revised_simplex_sparse(lp)\n",
    "    else\n",
    "        println(\"\\nSolving the reduced problem using the Revised Simplex Method with dense matrices\")\n",
    "        execution_time = @elapsed x, obj_value = revised_simplex(lp)\n",
    "    end\n",
    "end\n",
    "println(\"\\nExecution time: $execution_time seconds\")\n",
    "\n",
    "# show the solution\n",
    "\n",
    "println(\"\\nFinal solution:\")\n",
    "for (var, val) in zip(lp.vars, x[1:length(lp.vars)])\n",
    "    println(\"$var = $(round(val, digits=6))\")\n",
    "end\n",
    "println(\"Objective value: $(round(obj_value, digits=6))\")\n",
    "\n",
    "# A = [3.0 1.0 -3.0 2.0 1.0;\n",
    "#         2.0 2.0 1.0 -1.0 2.0;\n",
    "#         1.0 -1.0 2.0 2.0 -3.0]\n",
    "# b = [9.0, 10.0, 11.0]\n",
    "# c = [-1.0, -7.0, -6.0, -3.0, -4.0]  # Negated for maximization\n",
    "# vars = [\"X3\", \"X4\", \"X5\", \"X2\", \"X1\"]\n",
    "# lp = LPProblem(false, c, A, b, vars, ['≤', '≤', '≤'])\n",
    "\n",
    "# x, obj_value = highs_inspired_ipm(lp)\n",
    "\n",
    "# println(\"\\nSolution:\")\n",
    "# for (var, val) in zip(lp.vars, x)\n",
    "#     println(\"$var = $val\")\n",
    "# end\n",
    "# println(\"Objective value: \", -obj_value)  # Negated back for maximization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
